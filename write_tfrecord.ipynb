{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "feature_description = { # 定义Feature结构，告诉解码器每个Feature的类型是什么\n",
    "    'id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'tag_id': tf.io.VarLenFeature(tf.int64),\n",
    "    'category_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'title': tf.io.FixedLenFeature([], tf.string),\n",
    "    'asr_text': tf.io.FixedLenFeature([], tf.string),\n",
    "    'frame_feature': tf.io.VarLenFeature(tf.string)\n",
    "}\n",
    "\n",
    "\n",
    "def read_and_decode(example_string):\n",
    "    '''\n",
    "    从TFrecord格式文件中读取数据 train\n",
    "    '''\n",
    "    feature_dict = tf.io.parse_single_example(example_string, feature_description)\n",
    "    frame_feature = tf.sparse.to_dense(feature_dict['frame_feature']).numpy()\n",
    "    title = feature_dict['title'].numpy()\n",
    "    asr_text = feature_dict['asr_text'].numpy()\n",
    "    id = feature_dict['id'].numpy()\n",
    "    tag_id = tf.sparse.to_dense(feature_dict['tag_id']).numpy()\n",
    "    category_id = feature_dict['category_id'].numpy()\n",
    "\n",
    "\n",
    "    return id, tag_id, category_id, frame_feature, title, asr_text\n",
    "\n",
    "import glob\n",
    "def get_all_data(path): # 'data/pairwise'\n",
    "    filenames = glob.glob(path)\n",
    "    print(filenames)\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    datas = {}\n",
    "    for i, data in enumerate(dataset):\n",
    "        id, tag_id, category_id, frame_feature, title, asr_text = read_and_decode(data)\n",
    "        id = id.decode()\n",
    "        datas[id] = {'tag_id': tag_id, 'category_id': category_id, 'frame_feature': frame_feature, 'title': title, 'asr_text': asr_text}\n",
    "        # print(id)\n",
    "        # print(datas['2345203561710400875']['asr_text'])\n",
    "        # break\n",
    "        # if i % 10000 == 0 and i > 0:\n",
    "        #     break\n",
    "    return datas  \n",
    "\n",
    "datas = get_all_data('data/pairwise/pairwise.tfrecords')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(datas)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "label_path = 'data/pairwise/label.tsv'\n",
    "f = open(label_path)\n",
    "all_pair_data = []\n",
    "for line in f:\n",
    "    id_1, id_2, sim = line.strip().split('\\t')\n",
    "    sim = float(sim)\n",
    "    all_pair_data.append([id_1, id_2, sim])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "label_path_sup = 'data/pairwise/label_sup_0.9'\n",
    "f = open(label_path_sup)\n",
    "all_pair_data_sup = []\n",
    "for line in f:\n",
    "    id_1, id_2, sim = line.strip().split('\\t')\n",
    "    sim = float(sim)\n",
    "    all_pair_data_sup.append([id_1, id_2, sim])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# shuffle pair data and get the top 6000 for validation\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "# print(all_pair_data[:10])\n",
    "random.shuffle(all_pair_data)\n",
    "# print(all_pair_data[:10])\n",
    "val_pair_data = all_pair_data[:6000]\n",
    "train_pair_data = all_pair_data[6000:]+all_pair_data_sup"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "random.shuffle(train_pair_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def write_tfrecord(pair_datas, split):\n",
    "    write_path = 'data/pairwise/0-5999val_plus0.9/'+split+'.tfrecord'\n",
    "    writer = tf.io.TFRecordWriter(write_path) \n",
    "    for pair_data in tqdm(pair_datas): # [id_1, id_2, sim] [str, str, float]\n",
    "        id_1, id_2, sim = pair_data\n",
    "        tag_id_1 = datas[id_1]['tag_id']\n",
    "        category_id_1 = datas[id_1]['category_id']\n",
    "        frame_feature_1 = datas[id_1]['frame_feature'].tolist()\n",
    "        title_1 = datas[id_1]['title']\n",
    "        asr_text_1 = datas[id_1]['asr_text']\n",
    "\n",
    "        tag_id_2 = datas[id_2]['tag_id']\n",
    "        category_id_2 = datas[id_2]['category_id']\n",
    "        frame_feature_2 = datas[id_2]['frame_feature'].tolist()\n",
    "        title_2 = datas[id_2]['title']\n",
    "        asr_text_2 = datas[id_2]['asr_text']\n",
    "        feature = {                             # 建立 tf.train.Feature 字典\n",
    "            'id_1': tf.train.Feature(bytes_list=tf.train.BytesList(value=[bytes(id_1.encode())])),  \n",
    "            'tag_id_1': tf.train.Feature(int64_list=tf.train.Int64List(value=list(tag_id_1))),\n",
    "            'frame_feature_1': tf.train.Feature(bytes_list=tf.train.BytesList(value=frame_feature_1)),\n",
    "            'category_id_1': tf.train.Feature(int64_list=tf.train.Int64List(value=[category_id_1])),   \n",
    "            'title_1': tf.train.Feature(bytes_list=tf.train.BytesList(value=[title_1])),\n",
    "            'asr_text_1': tf.train.Feature(bytes_list=tf.train.BytesList(value=[asr_text_1])),\n",
    "            'id_2': tf.train.Feature(bytes_list=tf.train.BytesList(value=[bytes(id_2.encode())])),  \n",
    "            'tag_id_2': tf.train.Feature(int64_list=tf.train.Int64List(value=list(tag_id_2))),\n",
    "            'frame_feature_2': tf.train.Feature(bytes_list=tf.train.BytesList(value=frame_feature_2)),\n",
    "            'category_id_2': tf.train.Feature(int64_list=tf.train.Int64List(value=[category_id_2])),   \n",
    "            'title_2': tf.train.Feature(bytes_list=tf.train.BytesList(value=[title_2])),\n",
    "            'asr_text_2': tf.train.Feature(bytes_list=tf.train.BytesList(value=[asr_text_2])),\n",
    "            'sim': tf.train.Feature(float_list=tf.train.FloatList(value=[sim])) \n",
    "        }\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        writer.write(example.SerializeToString()) \n",
    "    writer.close()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "write_tfrecord(val_pair_data, 'val')\n",
    "write_tfrecord(train_pair_data, 'train')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filename = 'data/pairwise/0-5999val_plus0.9/val.tfrecord'\n",
    "dataset = tf.data.TFRecordDataset(filename)\n",
    "for i, line in enumerate(dataset):\n",
    "    # print(line)\n",
    "    example_proto = tf.train.Example.FromString(line.numpy())\n",
    "    print(example_proto)\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('tf2new': conda)"
  },
  "interpreter": {
   "hash": "d37efcbe9c2202a39089d2f79dc7610bc81d8aaeaad06d9afebeff464dd1736b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}